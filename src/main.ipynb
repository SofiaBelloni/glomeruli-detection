{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HJDIpn-_8HWj"
      },
      "source": [
        "# Things to install"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WlQ4_fPh8HWm"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY1phunv8HWm"
      },
      "outputs": [],
      "source": [
        "!apt update && apt install -y openslide-tools\n",
        "!pip install openslide-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xk9yXI5-2_B"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fL9vKIbZ8HWn"
      },
      "source": [
        "## Locale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sXDluubr8HWn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openslide-python in /Users/alessandrodemarco/opt/anaconda3/lib/python3.9/site-packages (1.2.0)\n",
            "Requirement already satisfied: Pillow in /Users/alessandrodemarco/opt/anaconda3/lib/python3.9/site-packages (from openslide-python) (9.2.0)\n",
            "Requirement already satisfied: opencv-python in /Users/alessandrodemarco/opt/anaconda3/lib/python3.9/site-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /Users/alessandrodemarco/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openslide-python\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e5gSArhj8HWo"
      },
      "outputs": [],
      "source": [
        "# The path can also be read from a config file, etc.\n",
        "OPENSLIDE_PATH = r'C:\\Users\\sofia\\openslide-win64-20230414\\openslide-win64-20230414\\bin'\n",
        "\n",
        "import os\n",
        "if hasattr(os, 'add_dll_directory'):\n",
        "    # Python >= 3.8 on Windows\n",
        "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
        "        import openslide\n",
        "else:\n",
        "    import openslide"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dBKMu2758HWo"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bO4PT-L98HWo"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6o0AMeE_8HWo"
      },
      "source": [
        "## Imports and env var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QqZY-5Za8HWo"
      },
      "outputs": [],
      "source": [
        "import openslide\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon\n",
        "import tensorflow as tf\n",
        "\n",
        "path_to_image = \"../slides/RECHERCHE-010.svs\"\n",
        "path_to_xml = \"../annotations/RECHERCHE-010.xml\"\n",
        "output_width = 2000\n",
        "output_height = 2000"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H7JoVxpH8HWp"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QJd8LBBx8HWp"
      },
      "outputs": [],
      "source": [
        "def get_annotatios(file_path):\n",
        "    # Parsa il file XML delle annotazioni\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    # Ottieni tutte le annotazioni dal file XML\n",
        "    annotations = []\n",
        "    for annotation in root.iter('Annotation'):\n",
        "        name = annotation.get('Name')\n",
        "        coordinates = []\n",
        "        for coordinate in annotation.iter('Coordinate'):\n",
        "            x = float(coordinate.get('X'))\n",
        "            y = float(coordinate.get('Y'))\n",
        "            coordinates.append((x, y))\n",
        "        annotations.append({'name': name, 'coordinates': coordinates})\n",
        "    return annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pif29E768HWp"
      },
      "outputs": [],
      "source": [
        "def is_mostly_white(image, threshold_w=0.85, threshold_p = 0.98):\n",
        "    # Converti l'immagine in scala di grigi\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calcola la soglia per considerare i pixel bianchi\n",
        "    pixel_threshold = int(threshold_w * 255)\n",
        "\n",
        "    # Conta i pixel bianchi nell'immagine\n",
        "    white_pixels = np.sum(gray_image >= pixel_threshold)\n",
        "\n",
        "    # Calcola la percentuale di pixel bianchi rispetto alla dimensione totale dell'immagine\n",
        "    white_percentage = white_pixels / (gray_image.shape[0] * gray_image.shape[1])\n",
        "\n",
        "    # Verifica se la percentuale di pixel bianchi supera la soglia\n",
        "    if white_percentage >= threshold_p:\n",
        "        return True, white_percentage\n",
        "    else:\n",
        "        return False, white_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "koi-zS_A8HWq"
      },
      "outputs": [],
      "source": [
        "def get_labels(labels, annotations):\n",
        "    for annotation in annotations:\n",
        "        polygon = np.array([annotation['coordinates']], dtype=np.int32)\n",
        "        cv2.fillPoly(labels, polygon, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FgxYl6Cl8HWq"
      },
      "outputs": [],
      "source": [
        "def plt_image_labels(image, labes):\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    # Primo subplot: labels\n",
        "    axs[0].imshow(labes)\n",
        "    axs[0].axis('off')\n",
        "    # Secondo subplot: immagine\n",
        "    axs[1].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    axs[1].axis('off')\n",
        "    # Mostra i subplot affiancati\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plt_image(image, labels):\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Sovrapposizione punti con labels=1\n",
        "    overlay = np.zeros_like(image)\n",
        "    overlay[np.where(labels == 1)] = [128, 128, 0]  # Giallo (BGR)\n",
        "    #overlay[np.where(labels == 0)] = [255, 255, 255]  # Giallo (BGR)\n",
        "    \n",
        "    alpha = 0.8  # Livello di trasparenza\n",
        "    overlay = cv2.addWeighted(image, 1, overlay, alpha, 0)\n",
        "\n",
        "    plt.imshow(overlay)  # Sovrapposizione con trasparenza\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y9oRPi-S8HWq"
      },
      "outputs": [],
      "source": [
        "def data_augment(image):\n",
        "    image_90 = np.rot90(image)\n",
        "    image_180 = np.rot90(image_90)\n",
        "    image_270 = np.rot90(image_180)\n",
        "    return image_90, image_180, image_270"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mLn-hWYT8HWq"
      },
      "source": [
        "## 'Main'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Zimbq2v28HWq"
      },
      "outputs": [],
      "source": [
        "# Carica l'immagine svs\n",
        "wsi = openslide.OpenSlide(path_to_image)\n",
        "# Ottieni le dimensioni dell'immagine\n",
        "w, h = wsi.dimensions\n",
        "# Calcola il numero di righe e colonne necessarie per suddividere l'immagine\n",
        "num_rows = h // output_height\n",
        "num_cols = w // output_width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37 88\n"
          ]
        }
      ],
      "source": [
        "print(num_rows, num_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "SBAVu6Aq8HWq"
      },
      "outputs": [],
      "source": [
        "annotations = get_annotatios(path_to_xml)\n",
        "# Crea un'immagine di output con le stesse dimensioni dell'immagine svs\n",
        "label_image = np.zeros((h, w), dtype=np.uint8)\n",
        "get_labels(label_image, annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "WVRhCQjv8HWr"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "labels = []\n",
        "\n",
        "#for row in range(num_rows):\n",
        "#    for col in range(num_cols):\n",
        "for row in range(3, 5):\n",
        "    for col in range(58, 60):\n",
        "        # Calcola le coordinate di inizio e fine per l'immagine corrente\n",
        "        x = col * output_width\n",
        "        y = row * output_height\n",
        "        x_end = x + output_width\n",
        "        y_end = y + output_height\n",
        "        \n",
        "        # Estrai l'immagine corrente\n",
        "        region = wsi.read_region((x, y), 0, (output_width, output_height))\n",
        "        image = cv2.cvtColor(np.array(region), cv2.COLOR_RGBA2BGR)\n",
        "        \n",
        "        is_white, p = is_mostly_white(image)\n",
        "        if not is_white:\n",
        "            if not ((col == num_cols-1) or (row == num_rows-1)):\n",
        "                x_h = x + output_width // 2 \n",
        "                x_v = x\n",
        "                x_d = x + output_width // 2 \n",
        "                y_h = y\n",
        "                y_v = y + output_height // 2\n",
        "                y_d = y + output_width // 2 \n",
        "                region_h = wsi.read_region((x_h, y_h), 0, (output_width, output_height))\n",
        "                region_v = wsi.read_region((x_v, y_v), 0, (output_width, output_height))\n",
        "                region_d = wsi.read_region((x_d, y_d), 0, (output_width, output_height))\n",
        "                image_h = cv2.cvtColor(np.array(region_h), cv2.COLOR_RGBA2BGR)\n",
        "                image_v = cv2.cvtColor(np.array(region_v), cv2.COLOR_RGBA2BGR)\n",
        "                image_d = cv2.cvtColor(np.array(region_d), cv2.COLOR_RGBA2BGR)\n",
        "                is_white_h, _ = is_mostly_white(image_h)\n",
        "                is_white_v, _ = is_mostly_white(image_v)\n",
        "                is_white_d, _ = is_mostly_white(image_d)\n",
        "                if not is_white_h:\n",
        "                    dataset.append(image_h)\n",
        "                    labels.append(label_image[y_h: y_h+output_height, x_h: x_h+output_width])\n",
        "                if not is_white_v:\n",
        "                    dataset.append(image_v)\n",
        "                    labels.append(label_image[y_v: y_v+output_height, x_v: x_v+output_width])\n",
        "                if not is_white_d:\n",
        "                    dataset.append(image_d)\n",
        "                    labels.append(label_image[y_d: y_d+output_height, x_d: x_d+output_width])\n",
        "            dataset.append(image)\n",
        "            labels.append(label_image[y:y_end, x: x_end])\n",
        "dataset = np.array(dataset)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "bOuglic1ADkB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16, 2000, 2000, 3)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j3mcptuB-Pl"
      },
      "outputs": [],
      "source": [
        "for i in range(len(dataset)):\n",
        "  plt_image(dataset[i], labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "G2RTOsd7Cddg"
      },
      "outputs": [],
      "source": [
        "np.save('dataset.npy', dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 2000, 2000, 3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = np.load('dataset.npy')\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.sum(data)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(output_width//2, output_height//2), \n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.25),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "resize = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(output_width, output_height),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(dataset)):\n",
        "    image = dataset[i]\n",
        "    #grayscaled = tf.image.rgb_to_grayscale(image)\n",
        "    #print(grayscaled.shape)\n",
        "    saturated = tf.image.adjust_saturation(image, 3)\n",
        "    print(saturated.shape)\n",
        "    bright = tf.image.adjust_brightness(image, 0.4)\n",
        "    print(bright.shape)\n",
        "    cropped = tf.image.central_crop(image, central_fraction=0.5)\n",
        "    cropped = resize(cropped)\n",
        "    print(cropped.shape)\n",
        "    dataset=np.append(dataset, [saturated, bright, cropped], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(dataset)):\n",
        "    # Primo subplot: labels\n",
        "    # Secondo subplot: immagine\n",
        "    plt.imshow(cv2.cvtColor(dataset[i], cv2.COLOR_BGR2RGB))\n",
        "    # Mostra i subplot affiancati\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "for i in range(100):\n",
        "    index = random.randint(0, len(data))\n",
        "    print(index)\n",
        "    plt_image(data[index], labels[index])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TODO\n",
        "* Non stampa le immagini perchè sono float e vuole int\n",
        "* Controllare con un'immagine di esempio i risultati delle modifiche\n",
        "* Controllare il resizing delle labels (potrebbe restituire forme rettangolare e che non rispiecchiano la forma del glomerulo)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
