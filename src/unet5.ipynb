{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jq8pDUlVtvX",
        "outputId": "04f9adc4-e9fe-4358-ebc9-89275acdf8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d0FYwBCZz0e"
      },
      "outputs": [],
      "source": [
        "import imgaug.augmenters as iaa\n",
        "import tensorflow as tf\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merging import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "path_to_dataset = \"/content/drive/MyDrive/Polito/MLinAP/RECHERCHE-015.npy\"\n",
        "path_to_labels = \"/content/drive/MyDrive/Polito/MLinAP/RECHERCHE-015_label.npy\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoL-MwT7VXjT"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1N1EopOVejK"
      },
      "outputs": [],
      "source": [
        "def data_augment():\n",
        "    return iaa.Sequential([\n",
        "        iaa.Dropout((0, 0.05)),  # Remove random pixel\n",
        "        iaa.Affine(rotate=(-30, 30)),  # Rotate between -30 and 30 degreed\n",
        "        iaa.Fliplr(0.5),  # Flip with 0.5 probability\n",
        "        iaa.Crop(percent=(0, 0.2), keep_size=True),  # Random crop\n",
        "        # Add -50 to 50 to the brightness-related channels of each image\n",
        "        iaa.WithBrightnessChannels(iaa.Add((-50, 50))),\n",
        "        # Change images to grayscale and overlay them with the original image by varying strengths, effectively removing 0 to 50% of the color\n",
        "        iaa.Grayscale(alpha=(0.0, 0.5)),\n",
        "        # Add random value to each pixel\n",
        "        iaa.GammaContrast((0.5, 2.0), per_channel=True),\n",
        "        # Local distortions of images by moving points around\n",
        "        iaa.PiecewiseAffine(scale=(0.01, 0.1)),\n",
        "    ], random_order=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2QOfZ3OVgvn"
      },
      "outputs": [],
      "source": [
        "def process_data(image, label):\n",
        "    return tf.cast(image, tf.float32)/255, tf.one_hot(label, 2, name=\"label\", axis=-1)\n",
        "    #return tf.cast(image, tf.float32)/255, label\n",
        "#Il one_hot (one hot encoding) è necessario se il modello è compilato con 'loss=\"categorical_crossentropy\"'\n",
        "#Nel nostro caso, vista la classificazione binaria, si può compilare il modello con 'loss=\"binary_crossentropy\"'\n",
        "#Questa NON richiede la one hot encoding!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1NRZBe4VicN"
      },
      "outputs": [],
      "source": [
        "def data_aug_impl(dataset, image_train, label_train):\n",
        "    da = data_augment()\n",
        "    segmented_label_train = [SegmentationMapsOnImage(\n",
        "        label, shape=dataset[1].shape) for label in label_train]\n",
        "    image_train_copy = image_train.copy()\n",
        "    for _ in range(1):\n",
        "        augmented_images, augmented_labels = da(\n",
        "            images=image_train_copy, segmentation_maps=segmented_label_train)\n",
        "        image_train = np.append(image_train, augmented_images, axis=0)\n",
        "        label_train = np.append(label_train, np.array(\n",
        "            [label.get_arr() for label in augmented_labels]), axis=0)\n",
        "\n",
        "    return image_train, label_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2RRuM8hVkII"
      },
      "outputs": [],
      "source": [
        "def generate_train_data_tensor(image_train, label_train):\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((image_train, label_train))\n",
        "    train_data = train_data.map(\n",
        "        process_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    train_data = train_data.cache()\n",
        "    train_data = train_data.shuffle(100)\n",
        "    train_data = train_data.batch(32)\n",
        "    train_data = train_data.prefetch(tf.data.AUTOTUNE)\n",
        "    return train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_iaDsbuVoZx"
      },
      "outputs": [],
      "source": [
        "dataset = np.load(path_to_dataset)[0:10]\n",
        "labels = np.load(path_to_labels)[0:10]\n",
        "image_train, image_test, label_train, label_test = train_test_split(\n",
        "    dataset, labels, test_size=0.25, random_state=42)\n",
        "#image_train, label_train = data_aug_impl(dataset, image_train, label_train)\n",
        "train_data = generate_train_data_tensor(image_train, label_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9D5AampXoZM",
        "outputId": "e41c34c8-679d-447e-86f7-3b46a7c44ac8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 512, 512, 2), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqc85m0VcYm"
      },
      "source": [
        "# U-net5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSBVGxAQaa9z",
        "outputId": "357d3527-c248-4056-f28b-0ba7e0c0dbe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1/1 [==============================] - 41s 41s/step - loss: 0.5117 - accuracy: 0.9168\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6338 - accuracy: 0.9187\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4667 - accuracy: 0.9187\n"
          ]
        }
      ],
      "source": [
        "class Unet(Model):\n",
        "\n",
        "  def __init__(self, dropout_value= 0.3, num_classes = 2, input_shape = (512, 512, 3)):\n",
        "    super().__init__()\n",
        "    vgg19 = tf.keras.applications.vgg19.VGG19(\n",
        "        include_top=False,   # Exclusion of the last 3 layers\n",
        "        weights='imagenet',\n",
        "        # input_tensor=None,\n",
        "        input_shape=input_shape,\n",
        "        pooling='max',\n",
        "        classes=num_classes,\n",
        "        classifier_activation='relu'\n",
        "    )\n",
        "    #for layer in vgg19.layers:\n",
        "    #  layer.trainable = False\n",
        "    #Block 1\n",
        "    self.b1c1 = vgg19.get_layer('block1_conv1')\n",
        "    self.b1c2 = vgg19.get_layer('block1_conv2')\n",
        "    #Block 2\n",
        "    self.b2p = vgg19.get_layer('block1_pool')\n",
        "    self.b2c1 = vgg19.get_layer('block2_conv1')\n",
        "    self.b2c2 = vgg19.get_layer('block2_conv2')\n",
        "    #Block 3\n",
        "    self.b3p = vgg19.get_layer('block2_pool')\n",
        "    self.b3c1 = vgg19.get_layer('block3_conv1')\n",
        "    self.b3c2 = vgg19.get_layer('block3_conv2')\n",
        "    #Block 4\n",
        "    self.b4p = vgg19.get_layer('block3_pool')\n",
        "    self.b4c1 = vgg19.get_layer('block4_conv1')\n",
        "    self.b4c2 = vgg19.get_layer('block4_conv2')\n",
        "    #Block 5\n",
        "    self.b5p = vgg19.get_layer('block4_pool')\n",
        "    self.b5c1 = vgg19.get_layer('block5_conv1')\n",
        "    self.b5c2 = vgg19.get_layer('block5_conv2')\n",
        "    #Block 6\n",
        "    #self.b6d1 = Dropout(dropout_value) #Controllando meglio su internet, sembrerebbe che il dropout non è presente nativamente su unet, ma è possibile inserirlo qualora si osservi dell'overfitting\n",
        "    self.b6p = vgg19.get_layer('block5_pool')\n",
        "    self.b6c1 = Conv2D(filters = 1024, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b6c2 = Conv2D(filters = 1024, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    #self.b6d2 = Dropout(dropout_value)\n",
        "    self.b6u = Conv2DTranspose(512, (3, 3), activation = \"relu\", strides = (2, 2), padding = 'same')\n",
        "    #Block 7\n",
        "    #After concatenate\n",
        "    self.b7c1 = Conv2D(filters = 512, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b7c2 = Conv2D(filters = 512, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b7u = Conv2DTranspose(512, (3, 3), activation = \"relu\", strides = (2, 2), padding = 'same')\n",
        "    #Block 8\n",
        "    #After concatenate\n",
        "    self.b8c1 = Conv2D(filters = 512, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b8c2 = Conv2D(filters = 512, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b8u = Conv2DTranspose(256, (3, 3), activation = \"relu\", strides = (2, 2), padding = 'same')\n",
        "    #Block 9\n",
        "    #After concatenate\n",
        "    self.b9c1 = Conv2D(filters = 256, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b9c2 = Conv2D(filters = 256, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b9u = Conv2DTranspose(128, (3, 3), activation = \"relu\", strides = (2, 2), padding = 'same')\n",
        "    #Block 10\n",
        "    #After concatenate\n",
        "    self.b10c1 = Conv2D(filters = 128, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b10c2 = Conv2D(filters = 128, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b10u = Conv2DTranspose(64, (3, 3), activation = \"relu\", strides = (2, 2), padding = 'same')\n",
        "    #Block 11\n",
        "    #After concatenate\n",
        "    self.b11c1 = Conv2D(filters = 64, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b11c2 = Conv2D(filters = 64, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b11c3 = Conv2D(filters = 64, activation='relu', kernel_size = (3, 3), kernel_initializer = 'he_normal', padding = 'same')\n",
        "    self.b11s = Conv2D(2, (1, 1), activation='softmax')\n",
        "\n",
        "  def call(self, input):\n",
        "    #Block 1\n",
        "    r1 = self.b1c1(input)\n",
        "    r1 = self.b1c2(r1)\n",
        "    #Block 2\n",
        "    r2 = self.b2p(r1)\n",
        "    r2 = self.b2c1(r2)\n",
        "    r2 = self.b2c2(r2)\n",
        "    #Block 3\n",
        "    r3 = self.b3p(r2)\n",
        "    r3 = self.b3c1(r3)\n",
        "    r3 = self.b3c2(r3)\n",
        "    #Block 4\n",
        "    r4 = self.b4p(r3)\n",
        "    r4 = self.b4c1(r4)\n",
        "    r4 = self.b4c2(r4)\n",
        "    #Block 5\n",
        "    r5 = self.b5p(r4)\n",
        "    r5 = self.b5c1(r5)\n",
        "    r5 = self.b5c2(r5)\n",
        "    #Block 6\n",
        "    #r6 = self.b6d1(r5)\n",
        "    r6 = self.b6p(r5)\n",
        "    r6 = self.b6c1(r6)\n",
        "    r6 = self.b6c2(r6)\n",
        "    #r6 = self.b6d2(r6)\n",
        "    r6 = self.b6u(r6)\n",
        "    #Block 7\n",
        "    r7 = concatenate([r6, r5]) \n",
        "    r7 = self.b7c1(r7)\n",
        "    r7 = self.b7c2(r7)\n",
        "    r7 = self.b7u(r7)\n",
        "    #Block 8\n",
        "    r8 = concatenate([r7, r4]) \n",
        "    r8 = self.b8c1(r8)\n",
        "    r8 = self.b8c2(r8)\n",
        "    r8 = self.b8u(r8)\n",
        "    #Block 9\n",
        "    r9 = concatenate([r8, r3]) \n",
        "    r9 = self.b9c1(r9)\n",
        "    r9 = self.b9c2(r9)\n",
        "    r9 = self.b9u(r9)\n",
        "    #Block 10\n",
        "    r10 = concatenate([r9, r2]) \n",
        "    r10 = self.b10c1(r10)\n",
        "    r10 = self.b10c2(r10)\n",
        "    r10 = self.b10u(r10)\n",
        "    #Block 11\n",
        "    r11 = concatenate([r10, r1]) \n",
        "    r11 = self.b11c1(r11)\n",
        "    r11 = self.b11c2(r11)\n",
        "    r11 = self.b11c3(r11)\n",
        "    out = self.b11s(r11)\n",
        "    return out \n",
        "        \n",
        "\n",
        "unet = Unet()\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01)\n",
        "unet.compile(optimizer=optimizer,\n",
        "               loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = unet.fit(train_data, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "optv_15iVU0O"
      },
      "outputs": [],
      "source": [
        "unet = Unet()\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01)\n",
        "unet.compile(optimizer=optimizer,\n",
        "               loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = unet.fit(train_data, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEB4GbMjd81s",
        "outputId": "4b3e5164-3c20-4d97-e481-9602c6e8ea2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        }
      ],
      "source": [
        "history = unet.fit(train_data, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l9-1X9veBpp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
